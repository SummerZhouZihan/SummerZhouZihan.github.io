---
layout:     post
title:      "蒙特卡洛理论及应用"
subtitle:   " \"计算机模拟课程笔记\""
date:       2025-11-21 16:00:00
author:     "Summer"
header-img: "img/head/image6.jpg"
catalog: true
mathjax: true
tags:
    - Mathematical Modeling
---

这是2025-2026秋冬计算机模拟的课程笔记. 因为秋学期实在太摆烂了, 冬学期要好好读一下PPT, 督促自己不要上课摸鱼了~

> 正在施工


## 8 马尔科夫链蒙特卡罗(MCMC)

### 8.1 简单蒙特卡洛(MC)方法的局限性

> **抽样效率**: 指 “用较少的样本量就能得到可靠结果” 的能力。效率越高，越能以低成本（时间 / 计算资源）完成估计；效率低则需要极多样本，甚至无法完成计算。

> **提议分布设计**: 在重要性抽样、拒绝 - 接受抽样中，需要先构造一个容易抽样的分布 q(x) 即 “提议分布”，再基于 q(x) 生成样本并修正，以逼近目标分布 p(x) 。

简单 MC 的局限集中在抽样效率和提议分布上：
- 直接抽样效率低：面对高维问题或稀有事件时，有效样本占比太少，需要极多样本才能得到可靠结果；
- 提议分布相关缺陷：
若提议分布 q(x) 与真实分布 p(x) 差异大，拒绝 - 接受 / 重要性抽样的效率会很低；构造 “匹配 p(x) 的好 q(x)” 本身很困难（因为实际中 p(x) 往往复杂未知）

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511221521297.png" width="600"/>

### 8.2 随机过程

**随机过程是随机变量的集合**，记为$\{X_t, t \in T\}$。

其中：
- $T$是“指标集”，可以是离散的（比如$T=\{1,2,3,...\}$，对应“随机变量序列”），也可以是连续的（比如$T=[0,+\infty)$）；
- 每个$X_t$是一个随机变量，整个集合描述了“随指标（通常是时间）变化的随机现象”。


常见的随机过程包括Poisson过程、Markov过程等。

#### 8.2.1 Poisson过程

**Poisson过程是描述“事件在时间轴上随机发生次数”的随机过程**. 

假设事件在$[0, t]$上任意时刻发生, $N(t)$表示$[0,t]$内事件发生的次数. 核心是满足3个条件的计数过程$N(t)$：

1. **初始条件**：$N(0)=0$（初始时刻事件发生次数为0）；
2. **独立增量**：任意不重叠的时间区间内，事件发生的次数相互独立（比如$[0,t_1]$和$[t_1,t_2]$内的发生次数无关）；
3. **增量服从Poisson分布**：对任意时间间隔$t>0$，任意起始时刻$s≥0$，区间$[s,s+t]$内事件发生$k$次的概率满足：
   $$
   P\{N(s+t)-N(s)=k\} = \frac{(\lambda t)^k e^{-\lambda t}}{k!}
   $$
   其中$\lambda>0$是“速率”（表示单位时间内事件发生的平均次数）。



<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511221529118.png" width="400"/>


简单说，Poisson过程是 **用来刻画随机、独立发生的事件的计数规律** 的模型（比如某路口单位时间内的车流量、客服中心的呼叫次数等）。

#### 8.2.2 Markov过程

**Markov过程是满足“无后效性”的随机过程**，核心特点是“未来的状态只依赖于当前状态，与过去的状态无关”。


对于随机过程$ X = \{X_t, t \in R\} $，若满足：
$$
P(X_{t+1} = x_{t+1} | X_0 = x_0, \dots, X_t = x_t) = P(X_{t+1} = x_{t+1} | X_t = x_t)
$$
简单说：**已知“现在”，“未来”的概率分布与“过去”无关**，这一性质叫“Markov性”（无后效性）。


- 状态可以是离散的（比如“晴、云、雨”），也可以是连续的；
- 指标集（通常是时间）可以是离散的（比如“每天的状态”）或连续的。

举个例子, 比如：
- 青蛙在荷花池的跳跃（下一个位置只和当前位置有关）；
- 天气变化（明天的天气只依赖今天的天气，和昨天无关）；
- 传染病受感染的人数
- 原子核中一自由电子的跳跃
- 人口增长过程
- 股价波动、布朗运动等。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511221533168.png" width="500"/>

#### 8.2.3 Markov Chain 马尔科夫链

**马尔可夫链（Markov Chain）是“离散时间下满足马尔可夫性的随机过程”**. 是按时间顺序排列的一系列状态序列：$ x^{(0)}, x^{(1)}, x^{(2)}, \dots, x^{(n)}, x^{(n+1)}, \dots $，描述状态之间“前后相继”的转换过程。

**连续时间Markov过程**
考虑随机过程 $ X = \{X_t, t \in R\} $，满足：
$$
P(X_{t+1} = x_{t+1} \mid X_0 = x_0, \dots, X_t = x_t) = P(X_{t+1} = x_{t+1} \mid X_t = x_t)
$$

**离散时间马尔可夫链**
- 描述了从状态 $ x_i $ 到状态 $ x_j $ 的转换的随机过程。
- 假设存在一个独立于时间的**固定概率** $ p_{ij} $，使得：
  $$
  P(x^{(n+1)} = i \mid x^{(n)} = j, x^{(n-1)} = i_{n-1}, \dots, x^{(0)} = i_0) = p_{ij}, n \geq 0.
  $$



**马尔科夫性**(无记忆性): 下一个状态的概率**只由当前状态决定**，与过去的所有状态无关：
$$
P(x^{(n+1)} = i \mid x^{(n)} = j, x^{(n-1)} = i_{n-1}, \dots, x^{(0)} = i_0) = p_{ij}
$$
其中 $ p_{ij} $ 是**固定的状态转移概率**（与时间无关）。

#### 8.2.4 转移概率矩阵

考虑一个特殊的情况, 在**齐次马尔可夫链**（状态转移概率与时间无关）中，定义概率 $ p_{ij} $ 为：

$$
p_{ij} = P(X_{t+1} = j \mid X_t = i)
$$

它表示“当前处于状态 $ i $ 时，下一个时刻转移到状态 $ j $ 的概率”。

- 非负性：$ p_{ij} \geq 0 $（概率不能为负）；
- 归一性：$ \sum_{j=0}^{\infty} p_{ij} = 1 $（从状态 $ i $ 转移到所有可能状态的概率之和为1）。

将所有状态的转移概率 $ p_{ij} $ 按“行（当前状态）、列（下一状态）”排列，组成的矩阵：
$$
P = \begin{pmatrix}
p_{00} & p_{01} & \dots \\
p_{10} & p_{11} & \dots \\
\vdots & \vdots & \vdots
\end{pmatrix}
$$
这个矩阵就叫 **（一步）转移概率矩阵** ，它完整描述了马尔可夫链中“状态之间的转移规律”——是转移概率的“模型化表达”。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511221716708.png" width="400"/>

简单说：**转移概率矩阵（转移概率模型）是用矩阵形式，统一记录马尔可夫链中所有状态间的转移概率，从而量化状态转移的规律**。

#### 8.2.5 平稳分布

**平稳分布是马尔可夫链在长期运行后状态概率不再变化的稳定分布**


如果一个**非周期**的Markov链有状态转移矩阵$ P $，并且它的任意两个状态是**连通的**，那么：
$$
\lim_{n \to \infty} P_{ij}^n = \pi(j) = \sum_{i=1}^{\infty} \pi_i P_{ij}
$$
存在且与$ i $无关，即
$$
\lim_{n \to \infty} P^n = \begin{pmatrix}
\pi(1) & \pi(2) & \dots & \pi(j) & \dots \\
\pi(1) & \pi(2) & \dots & \pi(j) & \dots \\
& & \dots & & \\
\pi(1) & \pi(2) & \dots & \pi(j) & \dots \\
& & \dots & &
\end{pmatrix}
$$


其中，状态概率分布 $ \pi(j) = \sum_{i=1}^{\infty} \pi_i P_{ij} $。此外：
- $ \pi $是方程$ \pi P = \pi $的**唯一非负解**；
- $ \pi = [\pi(1), \pi(2), \dots, \pi(j), \dots] $满足$ \sum_{i=1}^{\infty} \pi_i = 1 $。


此时，我们称$ \pi $是这个Markov链的**平稳分布**。


直观来说：当马尔可夫链的状态概率分布达到 $ \pi $ 后，再经过一次转移，概率分布依然是 $ \pi $（状态概率不再随时间变化）。

<span style="font-size: 20px; color: #C25759;">Perron-Frobenius 定理</span>



如果概率转移矩阵$ P $满足：
$$ p_{i,j} > \delta > 0,\ \forall\ i,j $$

即从任意状态 $i$ 转移到任意状态 $j$ ，都有至少 $δ$ 的概率. 那么，有以下结论：

1\. $ P $存在特征值为1的**唯一左特征向量$ \vec{w} $**, 即满足 $\vec{w} P = 1 \cdot \vec{w}$，且$ \vec{w} $的所有分量严格为正；
2\. 若将此特征向量**归一化**（即满足$ \sum w_i = 1 $），则：
$$ \lim_{n \to \infty} P^n = \vec{1}\vec{w} $$
（其中$ \vec{1} $是全1列向量，$ \vec{1}\vec{w} $表示每一行均为$ \vec{w} $的矩阵）

也就是说, 无论初始状态是什么，经过足够多步转移后，系统处于各状态的概率都会收敛到$ \vec{w} $（即平稳分布）。

<span style="font-size: 20px; color: #C25759;">细致平稳条件/定理</span>

细致平稳条件的核心等式为：
$$ \pi_i p_{i,j} = \pi_j p_{j,i} \tag{1} $$

即 “从状态$i$到$j$的概率流” 等于 “从$j$到$i$的概率流”，则称$π$和$P$满足细致平稳条件。

只要满足细致平稳条件，就能直接推导出平稳分布的核心要求. 要验证转移矩阵$ P $达到平稳分布$ \pi $，需满足平稳分布的核心方程：

$$ \pi_j = \sum_{i=1}^{\infty} \pi_i p_{i,j} \tag{2} $$


利用细致平稳条件（1），可推导方程（2）成立：
$$
\sum_{i=1}^{\infty} \pi_i p_{i,j} = \sum_{i=1}^{\infty} \pi_j p_{j,i} = \pi_j \sum_{i=1}^{\infty} p_{j,i} = \pi_j
$$
（注：$ \sum_{i=1}^{\infty} p_{j,i} = 1 $是转移矩阵的行和为1的性质）


至此，平稳分布的核心方程（2）得证。


> 所有的 MCMC（Markov Chain Monte Carlo）方法都是以这个定理作为理论基础的！


<span style="font-size: 20px; color: #C25759;">案例1</span>

我们来看一个案例. **市场状态（牛、熊、平）构成的马尔可夫链，如何收敛到平稳分布**

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511221728238.png" width="400"/>

- **状态**：3种市场状态——牛、熊、平；
- **转移矩阵 $ P $**：描述状态间的转移概率（行是当前状态，列是下一状态）：
  $$
  P = \begin{pmatrix}
  0.9 & 0.075 & 0.025 \quad \text{（当前是“牛”，转牛/熊/平的概率）} \\
  0.15 & 0.8 & 0.05 \quad \text{（当前是“熊”，转牛/熊/平的概率）} \\
  0.25 & 0.25 & 0.5 \quad \text{（当前是“平”，转牛/熊/平的概率）}
  \end{pmatrix}
  $$
- **初始状态分布 $ s $**：初始时处于“牛、熊、平”的概率是 $ [0.12, 0.23, 0.65] $。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511221730197.png" width="300"/>

通过循环让初始分布 $ s $ 不断乘以转移矩阵 $ P $（模拟状态随时间的转移），可以看到：
- 初始几步（比如Step2），分布变化较大；
- 随着迭代次数增加（到Step40左右），分布逐渐稳定在 $ [0.62500, 0.31250, 0.06250] $；
- 之后无论再迭代多少次，分布都不再变化。


最终稳定的 $ [0.625, 0.3125, 0.0625] $ 就是这个马尔可夫链的**平稳分布**. 意味着“长期来看，市场处于‘牛’的概率是62.5%，‘熊’是31.25%，‘平’是6.25%”，且这个概率会保持稳定, 不再随时间变化。

<span style="font-size: 20px; color: #C25759;">案例2 : 周期性转移</span>


- **状态**：3个状态（1、2、3）；
- **转移概率矩阵 $ P $**：
  $$
  P = \begin{pmatrix}
  0 & 1 & 0 \quad \text{（状态1只能转移到状态2）} \\
  0.5 & 0 & 0.5 \quad \text{（状态2以0.5概率转移到1或3）} \\
  0 & 1 & 0 \quad \text{（状态3只能转移到状态2）}
  \end{pmatrix}
  $$
- **转移图规律**：状态1→2→1/3→2→1/3…，呈现“2步一循环”的周期特征。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511221758476.png"/>

通过计算转移矩阵的幂可以验证：$ P^3 = P $（即3次转移等价于1次转移），说明该马尔可夫链的**周期为2**——从任意状态出发，回到原状态的步数必须是2的倍数（比如状态1→2→1，需要2步；状态3→2→3，也需要2步）。

尽管是周期链，它存在**不变分布（不是平稳分布）**：$ \pi = (0.3636, 0.2397, 0.3967) $。

注意, 周期链的不变分布是“长期平均的状态占比”，状态不会固定在某一分布，而是按周期波动, 长期均值稳定。

> 所有马尔可夫链都有状态转移矩阵， “非周期” 是平稳分布存在且唯一的必要条件之一. 周期的马尔可夫链，状态会陷入 “固定间隔的循环”，导致转移矩阵的幂 $P^{n}$ 没有稳定的极限，因此不存在平稳分布（或无法收敛到唯一的平稳分布）。

#### 8.2.6 马尔科夫链的平稳性分析

**实用马尔科夫链**, 指能稳定应用（比如用于预测、建模）的马尔可夫链. 
- 状态数有限（不能有无穷多状态）；
- 转移概率固定（状态之间的转换概率不随时间变）；
- 任意状态可互通（从任意一个状态，能通过若干步转到其他任意状态）；
- 无简单循环（不会陷入 “A→B→A” 这种死循环，无法收敛）。

### 8.3 马尔科夫链蒙特卡洛

MCMC抽样（马尔可夫链蒙特卡洛，Markov Chain Monte Carlo）是一种非常强大的统计方法，它的核心思想是：

当你无法直接从一个非常复杂的目标（比如一个形状极其古怪的山）上随机取样（比如随机空投抓人）时，MCMC提供了一种“间接”的取样方法。

它通过构造一个“智能”的随机游走过程（马尔可夫链），让这个游走过程最终在山上“待得久”的地方，恰好就是山峰（概率高）的地方。这样，你只需要记录下这个游走者的足迹，就相当于得到了你想要的样本。

**蒙特卡洛**是一种思想，指通过大量的随机抽样来估算一个（通常很难直接计算的）结果。例如投掷针估算圆周率. 但是蒙特卡洛方法的前提是你能做到“真正的随机抽样”（比如在正方形内均匀地扔石头）。但如果目标分布（比如那个湖的形状）非常复杂、维度非常高，你根本没法直接进行均匀抽样。这时就需要马尔可夫链登场了。

**马尔科夫链**是一个随机过程，它有一个关键特性，叫做“无记忆性”。过程中的下一个状态只取决于当前状态，而与“如何”到达当前状态的“历史路径”完全无关。而**平稳分布**说明, 只要这个“马尔可夫链”设计得当（满足某些条件，比如不可约性和对称性），无论它从什么状态开始，在它随机游走了足够长的时间后，它处于各个状态的概率会趋于一个稳定的分布。

我们的目标是想从一个特定的、复杂的概率分布 $P(x) $中抽样。我们的方法是设计一个马尔可夫链，当马尔可夫链运行足够久、达到平稳分布后, 链上的状态恰好就是我们想要的那个 $P(x)$. 

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511231423760.png" width="500"/>

经典的MCMC采样流程：
1. **初始化**：设定马尔可夫链的初始状态$ X_0 = x_0 $；
2. **迭代采样**（对每一步$ t $）：
   - 基于当前状态$ X_t = x_t $，从**建议分布** $ q(x|x_t) $ 中采样一个候选状态$ y $；
   - 从均匀分布$ U[0,1] $中采样一个随机数$ z $；
   - 计算**接受概率**$ \alpha(x_t, y) = \min\left(1, \frac{p(y)q(x_t|y)}{p(x_t)q(y|x_t)}\right) $；
   - 比较$ z $和$ \alpha $：若$ z < \alpha $，则接受转移（$ X_{t+1} = y $）；否则拒绝转移（$ X_{t+1} = x_t $）。


通过“构造满足细致平稳条件的转移规则（接受/拒绝）”，让马尔可夫链的平稳分布等于目标分布$ p(X) $；当链收敛到平稳后，后续的状态就是$ p(X) $的有效样本。

<span style="font-size: 20px; color: #C25759;">案例1 : 改进的拒绝/接收采样</span>

下面, 我们 **使用MCMC（改进的接受-拒绝采样）从Γ分布中生成样本**

要采样的目标概率密度函数是Γ分布：

$$ f(x) = 0.5x^2e^{-x} $$

这个分布无法直接用简单方法采样，因此用MCMC的接受-拒绝逻辑生成样本

```matlab
N = 40000;                  % 1. 设定采样总次数为40000次
f = inline('0.5*x*x*exp(-x)','x');  % 2. 定义目标分布f(x)
d = zeros(1,N);             % 3. 初始化存储样本的数组d
x = 2;                      % 4. 设定Markov链的初始状态x=2
for i = 1:N                 % 5. 开始迭代采样
    y = x - 1 + 2*rand();   % 6. 从建议分布采样候选状态y：这里用的是“当前x附近的均匀分布”（范围[x-1, x+1]）
    if y < 0                % 7. 保证y非负（因为Γ分布的x≥0）
        y = x;              % 若y<0，拒绝这个候选，保持y=x
    end
    h = min(1, f(y) / f(x));% 8. 计算接受概率h：取“f(y)/f(x)”和1的较小值（避免概率大于1）
    U = rand;               % 9. 从均匀分布U[0,1]采样随机数U
    if (U < h)              % 10. 比较U和h：若U<h，接受候选状态y
        x = y;
    end
    d(i) = x;               % 11. 记录当前状态x（无论是否转移，都存入样本数组）
end
a = 0:0.08:20;              % 12. 设定直方图的区间
hist(d(floor(N / 2):end), a);  % 13. 绘制后20000个样本的直方图（前半部分是“燃烧期”，丢弃以保证样本是平稳分布）
```


<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511231439880.png" width="400"/>


直方图是采样20000次（取后20000个样本）的结果，形状与目标Γ分布$ 0.5x^2e^{-x} $一致，说明MCMC采样成功生成了该分布的样本。

<span style="font-size: 20px; color: #C25759;">模拟 “掷双骰子点数和” 的分布</span>

这个例子是**用MCMC的“极小邻域法”模拟“掷双骰子点数和”的分布**（目标分布是双骰子点数和的概率分布），具体逻辑和步骤如下：

掷两个骰子，点数和$ x $的可能取值是2~12，其**未归一的概率密度$ f(x) $**（对应出现的次数）为：
| $ x $ | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10 | 11 | 12 |
|--------|---|---|---|---|---|---|---|---|----|----|----|
| $ f(x) $ | 1 | 2 | 3 | 4 | 5 | 6 | 5 | 4 | 3 | 2 | 1 |

我们先用MCMC的极小邻域法生成这个分布的样本。

极小邻域法的核心是**为每个状态$ x $定义“只在相邻状态转移”的建议分布$ g(y|x) $**：
- 对当前状态$ x $，候选状态$ y $只能是“$ x-1 $”或“$ x+1 $”（边界状态做限制：$ x=2 $时只能转移到3，$ x=12 $时只能转移到11）；
- 转移到相邻状态的概率各为$ 1/2 $，即：

$$
g(y|x) =
\begin{cases}
1/2, & y = \max\{x-1, 2\} \quad (\text{左邻域}) \\
1/2, & y = \min\{x+1, 12\} \quad (\text{右邻域}) \\
0, & \text{其他}
\end{cases}
$$

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511231453320.png" width="400"/>

对应的建议分布矩阵$ G $（行是当前状态，列是候选状态）中，只有“当前状态±1”的位置为$ 1/2 $，其余为0（比如状态2的建议分布是“2→2（实际是$ \max(2-1,2)=2 $）和2→3，各1/2”）。

代码通过MCMC的“建议-接受”逻辑生成样本，步骤如下：
```matlab
f = [1,2,3,4,5,6,5,4,3,2,1];  % 1. 目标分布的未归一密度（对应x=2~12）
d = zeros(1,50000);            % 2. 存储50000个样本的数组
x = 5;                         % 3. 初始化Markov链的初始状态（比如x=5）
for i = 1:50000                % 4. 迭代采样
    U = rand();                % 5. 采样均匀分布随机数，决定转移方向
    if (U < 0.5)
        y = max(x - 1, 2);     % 左邻域：x-1，最小不小于2
    else
        y = min(x + 1, 12);    % 右邻域：x+1，最大不大于12
    end
    % 6. 计算接受概率：f(y)/f(x)与1的较小值（f是未归一密度，不影响比例）
    h = min(1, f(y - 1) / f(x - 1));  % 注：f的索引是y-2+1=y-1（因为x从2开始）
    U = rand();                % 7. 再采样一个均匀分布随机数
    if (U < h)                 % 8. 若U<h，接受转移；否则保持当前状态
        x = y;
    end
    d(i) = x;                  % 9. 记录当前状态为样本
end
% 10. 绘制后20000个样本的直方图（丢弃前30000个“燃烧期”样本）
histogram(d(30000:end), 2:12);
```

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511231454419.png" width="400"/>

直方图的形状与双骰子点数和的目标分布（中间7最高，向两边递减）一致，说明极小邻域法成功生成了目标分布的样本。

我们再使用极大邻域法解决这个问题. 

极大邻域法的建议分布是**从当前状态可以等概率转移到所有可能状态**：
双骰子点数和的状态是2~12（共11个状态），因此建议分布矩阵$ G $的每个元素都是$ \frac{1}{11} $，即：
$$
G = \begin{pmatrix}
\frac{1}{11} & \frac{1}{11} & \dots & \frac{1}{11} \\
\frac{1}{11} & \frac{1}{11} & \dots & \frac{1}{11} \\
\vdots & \vdots & & \vdots \\
\frac{1}{11} & \frac{1}{11} & \dots & \frac{1}{11}
\end{pmatrix}
$$
含义：从任意当前状态$ x $，候选状态$ y $可以是2~12中的**任意一个状态**，且每个状态的转移概率都是$ \frac{1}{11} $。


代码通过“全状态随机建议+接受-拒绝”生成样本，步骤如下：
```matlab
f = [1,2,3,4,5,6,5,4,3,2,1];  % 1. 目标分布的未归一密度（对应x=2~12）
d = zeros(1,40000);            % 2. 存储40000个样本的数组
x = 5;                         % 3. 初始化Markov链的初始状态（比如x=5）
for i = 1:40000                % 4. 迭代采样
    % 5. 从所有状态（2~12）中等概率采样候选状态y：randi(11,1)生成1~11，+1后得到2~12
    y = randi(11, 1) + 1;      
    % 6. 计算接受概率：f(y)/f(x)与1的较小值（f是未归一密度，比例不变）
    h = min(1, f(y - 1) / f(x - 1));  % 注：f的索引是y-2+1=y-1（x从2开始）
    U = rand();                % 7. 采样均匀分布随机数U~U[0,1]
    if (U < h)                 % 8. 若U<h，接受转移；否则保持当前状态
        x = y;
    end
    d(i) = x;                  % 9. 记录当前状态为样本
end
% 10. 绘制后10000个样本的直方图（丢弃前30000个“燃烧期”样本）
hist(d(30000:end), 1:11);
```

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511231459564.png" width="400"/>

直方图的形状与双骰子点数和的目标分布（中间7最高，向两边递减）一致，说明极大邻域法也成功生成了目标分布的样本。

极小邻域法 **仅在相邻状态间转移**（建议分布是局部的）；极大邻域法 **在所有状态间等概率转移**（建议分布是全局的）；两者都通过“接受概率”保证链的平稳分布匹配目标分布，只是建议分布的范围不同。

#### 8.3.1 Metropolis–Hastings 采样

Metropolis–Hastings（简称M-H）采样是**最经典的MCMC方法之一**，用于从复杂概率分布中生成样本. 

M-H采样的核心是**构造“接受概率”**，保证马尔可夫链的平稳分布等于目标分布$ f(x) $（或$ p(x) $）。接受概率的公式为：
$$ h(x, y) = \min\left\{1,\ \frac{f(y) \cdot g(x|y)}{f(x) \cdot g(y|x)}\right\} $$
其中$ x $是当前状态，$ y $是从**建议分布**$ g(y|x) $中采样的候选状态；$ g(x|y) $是从候选状态$ y $转移回$ x $的建议分布概率。

具体算法如下

1. **初始化**：设定马尔可夫链的初始状态$ X_0 = x_0 $；
2. **迭代采样**（对每一步$ t $）：
   - 基于当前状态 $ X_t = x_t $，从建议分布 $ g(y|x_t) $中采样候选状态$ y $；
   - 从均匀分布 $ U[0,1] $ 中采样随机数 $ u $；
   - 计算接受概率 $ h(x_t, y) = \min\left\{1,\ \frac{f(y)g(x_t|y)}{f(x_t)g(y|x_t)}\right\} $；
   - 若 $ u < h(x_t, y) $，**接受转移**（令$ X_{t+1} = y $）；否则**拒绝转移**（令$ X_{t+1} = x_t $）。

M-H是Metropolis算法的**推广**, **Metropolis算法** 是M-H的特殊情况，要求建议分布是**对称的**（即$ g(y|x) = g(x|y) $），此时接受概率简化为：

$$ h(x, y) = \min\left\{1,\ \frac{f(y)}{f(x)}\right\} $$

**M-H算法** 将建议分布推广到**非对称情形**（只需满足“可逆性”：$ g(y|x) > 0 \iff g(x|y) > 0 $），适用范围更广。

Metropolis算法有效的核心原因是, 它构造的马尔可夫链**满足“细致平稳条件”**，而细致平稳条件是马尔可夫链收敛到目标平稳分布的关键。以下是具体推导逻辑：

<span style="font-size: 20px; color: #C25759;">证明Metropolis算法有效</span>

要证明Metropolis算法有效，只需验证其对应的马尔可夫链满足**细致平稳条件**：

$$ f(x) P(x \to y) = f(y) P(y \to x) $$

其中$ f(x) $是目标分布；$ P(x \to y) $是从状态$ x $转移到$ y $的概率。

在Metropolis算法中，从$ x $到$ y $的转移概率由**建议分布**和**接受概率**共同决定：
$$ P(x \to y) = g(y|x) \cdot h(x,y) $$
其中：
- $ g(y|x) $是建议分布（Metropolis算法中要求它是**对称的**，即$ g(y|x) = g(x|y) $）；
- $ h(x,y) = \min\left\{1, \frac{f(y)}{f(x)}\right\} $是接受概率。

我们需要证明：$ f(x) \cdot h(x,y) = f(y) \cdot h(y,x) $（结合对称的建议分布$ g(y|x)=g(x|y) $，即可推出$ f(x)P(x\to y)=f(y)P(y\to x) $）。

分两种情况讨论：

**情况1：$ f(x) > f(y) $**
  此时接受概率$ h(x,y) = \frac{f(y)}{f(x)} $，而$ h(y,x) = 1 $（因为$ f(y) < f(x) $，$ \min\left\{1, \frac{f(x)}{f(y)}\right\}=1 $）。
  代入得：$ f(x) \cdot h(x,y) = f(x) \cdot \frac{f(y)}{f(x)} = f(y) $，$ f(y) \cdot h(y,x) = f(y) \cdot 1 = f(y) $，两者相等。


**情况2：$ f(x) < f(y) $**
  此时接受概率$ h(x,y) = 1 $，而$ h(y,x) = \frac{f(x)}{f(y)} $。
  代入得：$ f(x) \cdot h(x,y) = f(x) \cdot 1 = f(x) $，$ f(y) \cdot h(y,x) = f(y) \cdot \frac{f(x)}{f(y)} = f(x) $，两者也相等。

无论$ f(x) $和$ f(y) $的大小关系如何，都能验证 $ f(x)h(x,y) = f(y)h(y,x) $。结合对称的建议分布$ g(y|x)=g(x|y) $，可进一步推出：

$$ f(x) P(x \to y) = f(y) P(y \to x) $$

这说明Metropolis算法构造的马尔可夫链满足细致平稳条件，因此其平稳分布就是目标分布$ f(x) $——这就是Metropolis算法有效的根本原因。

#### 8.3.2 MCMC的其他性质

<span style="font-size: 20px; color: #C25759;">MCMC遍历性定理</span>

MCMC的遍历性定理是**保证MCMC能用于计算目标分布期望的核心理论**，它明确了“马尔可夫链的样本均值可以收敛到目标分布期望”的条件和结论，具体解释如下：

要应用遍历性定理，马尔可夫链需要满足：
1. **不可约**：任意两个状态之间可以通过有限步转移到达（状态连通）；
2. **非周期**：状态的周期为1（不会陷入固定间隔的循环）；
3. **平稳分布为 $\pi$**：马尔可夫链收敛到目标分布$\pi$。

若马尔可夫链满足上述条件，且$\xi: \Omega \to \mathbb{R}$是任意一个关于状态的函数（比如状态的某个统计量），则当样本数$N$趋于无穷大时， **样本均值会收敛到目标分布$\pi$下的期望** ：

$$
\lim_{N \to \infty} \frac{1}{N} \sum_{i=1}^N \xi(x_i) = E_{\pi}(\xi)
$$

其中：
- $x_1, x_2, \dots, x_N$是马尔可夫链达到平稳后生成的样本；
- $E_{\pi}(\xi)$是函数$\xi$在目标分布$\pi$下的期望。

遍历性定理解决了MCMC的“实用价值”问题, 仅让马尔可夫链收敛到平稳分布还不够，遍历性保证了**用平稳后的样本计算的均值，能逼近目标分布的期望**. 

<span style="font-size: 20px; color: #C25759;">MCMC收敛性与稳定性</span>

传统独立采样的收敛性. 对于**独立同分布（i.i.d.）的样本**（比如从分布中直接抽取的$ X_1,X_2,\dots,X_n $）：
用**样本均值**估计分布的未知期望$ \mu = E(X) $：
   $$
   \bar{X}(n) = \frac{1}{n} \sum_{j=1}^n X_j
   $$
样本均值的方差随样本量增大而减小：
   $$
   Var(\bar{X}(n)) = \frac{\sigma^2}{n} \quad (\sigma^2是分布的方差)
   $$
由**中心极限定理**，样本均值的标准化形式会**渐进服从正态分布**：
   $$
   Z_n = \frac{\sqrt{n}}{\sigma} (\bar{X}(n) - \mu) \xrightarrow{n\to\infty} \mathcal{N}(0,1)
   $$
即当样本量足够大时，样本均值与真实期望的偏差会近似服从标准正态分布。

MCMC采样的样本是**马尔可夫链的状态**（不是独立同分布的），但遍历性定理保证了：
- 当马尔可夫链满足“不可约、非周期、收敛到平稳分布”时，**平稳后的样本均值也会收敛到目标分布的期望**（类似传统采样的样本均值收敛）；
- 同时，MCMC样本的“渐进正态性”也成立（只是方差需要考虑马尔可夫链的相关性，会引入额外的“自相关系数”修正，但核心收敛逻辑与传统采样一致）。

MCMC的“收敛性”指**样本均值收敛到目标分布的期望**，“稳定性”指**样本均值的波动随样本量增大而减小，且渐进服从正态分布**——这与传统独立采样的收敛逻辑一致，只是MCMC是通过马尔可夫链的平稳性实现的。

<span style="font-size: 20px; color: #C25759;">MCMC误差估计</span>

MCMC的误差估计是**基于中心极限定理，量化“样本均值估计目标分布期望”的随机误差**，核心逻辑是用“置信区间”来描述估计的不确定性. 


MCMC的误差是**随机性误差**（和普通数值方法的确定性误差不同），因为MCMC样本是马尔可夫链生成的随机样本，估计结果会随样本不同而波动。

利用**勒维-林德伯格中心极限定理**，当MCMC样本量$ n \to \infty $时，样本均值$ \bar{X}(n) $与目标期望$ \mu $的偏差满足：
$$
\lim_{n \to \infty} \text{Pr}\left( (\bar{X}(n) - \mu) \leq X_{\alpha} \frac{\sigma}{\sqrt{n}} \right) = \frac{1}{\sqrt{2\pi}} \int_{-X_{\alpha}}^{X_{\alpha}} \exp\left(-\frac{t^2}{2}\right) dt = 1 - \alpha
$$
其中：
- $ \sigma^2 $是目标分布的方差；
- $ X_{\alpha} $是**正态差**（对应标准正态分布的分位数，比如$ \alpha=0.05 $时，$ X_{\alpha}\approx1.96 $）；
- $ \alpha $是**置信概率（显著水平）**，$ 1-\alpha $是**置信水平**（比如$ 1-\alpha=0.95 $表示“有95%的概率，偏差不超过$ X_{\alpha}\frac{\sigma}{\sqrt{n}} $”）。

MCMC估计的**绝对误差**（样本均值与真实期望的偏差上限）为：
$$
\varepsilon_{\alpha} = \left| \frac{1}{n}\sum_{i=1}^n X_i - \mu \right| = X_{\alpha} \frac{\sigma}{\sqrt{n}}
$$
含义：在置信水平$ 1-\alpha $下，样本均值与真实期望的偏差不会超过$ X_{\alpha}\frac{\sigma}{\sqrt{n}} $。


简言之，MCMC的误差估计是通过中心极限定理，用“正态分布的分位数+分布方差+样本量”来量化估计的随机误差，最终得到一个有概率保证的误差上限。


## 9 模拟退火 -- 统计物理




## 10 仿真优化算法 -- 非线性优化

### 10.1 遗传算法

一种模拟生物在自然环境中的遗传和进化的过程而形成的自适应全局优化概率搜索算法

五个核心要素：参数编码、种群初始化、遗传算子设计、适应度函数设计、控制参数

<span style="font-size: 20px;color: #4F845C;">求`shekel`函数最小值</span>

Shekel函数在这里是一个**单变量测试函数**，常用于优化算法（比如遗传算法）的性能测试，它的用法可以从这几个方面理解：

先把`shekel`函数保存为`.m`文件（比如`shekel.m`），代码功能是**计算输入`x`对应的函数值**：

```matlab
function y = shekel(x)
    % 输入：x（单个数值或数组）
    % 输出：y（对应x的shekel函数值）
    y = 1./(10.295*(x-7.382).^2 + 0.1613) + ...
        1./(4.722*(x-1.972).^2 + 0.2327) + ...
        1./(10.928*(x-8.111).^2 + 0.2047);
end
```

这个Shekel函数是**求最小值的目标函数**（因为优化任务是找它在`2≤x≤9`的最小值）。

在全局优化中（比如用Matlab的遗传算法`ga`），它的角色是：
- 算法会不断尝试不同的`x`（在`2~9`区间内），调用`shekel(x)`计算函数值；
- 最终找到使`shekel(x)`最小的`x`（即“最小点”）和对应的函数值（即“最小值”）。

用Matlab全局优化工具箱的`ga`（遗传算法）求解时，代码格式是：

```matlab
[x, v] = ga(@shekel, 1, [], [], [], [], 2, 9);
```

- `@shekel`：指定目标函数是`shekel`；
- `1`：变量个数（这里是单变量`x`）；
- 中间的`[]`：遗传算法的约束/参数默认值；
- `2, 9`：变量`x`的上下界（`2≤x≤9`）；
- 输出`x`：使`shekel(x)`最小的自变量值；
- 输出`v`：对应的最小值（即`shekel(x)`）。

#### 10.1.1 参数编码

目的: 将优化问题转换为组合问题

常用编码方案: 二进制编码、整数编码、实数编码

1\. **二进制编码**. 把变量转化为**二进制字符串（0和1组成）**的形式。
- 例子：若变量`x∈[0,10]`，精度到0.1，则需要`log2(10/0.1)=7`位二进制（比如`1010101`对应某个x值）。
- 优势：编码/解码简单、遗传操作（交叉/变异）容易实现、种群多样性好。
- 劣势：编码长度可能很长（精度越高越长）、不能直接体现变量的实际意义。


2\. **整数编码**. 把变量直接用**整数**表示（适用于变量本身是整数的问题）。
- 例子：求解“安排5个任务的顺序”，变量是任务编号`1、2、3、4、5`，直接用整数序列`[3,1,5,2,4]`表示解。
- 优势：适合整数类优化问题（如调度、排列）、编码简洁。
- 劣势：只适用于整数变量，不适合连续型变量。

3\. **实数编码**. 直接用变量的 **实际数值(浮点数)** 作为编码（适用于连续型变量）。
- 例子：变量`x∈[2,9]`，直接用`4.86`（Shekel函数的最小点）作为编码。
- 优势：无需编码/解码、能直接反映变量的实际意义、适合连续优化问题。
- 劣势：遗传操作（如变异）需控制范围（避免偏离解空间）、容易提前收敛（种群多样性不足）。

4\. **格雷码**

核心特点是“相邻整数对应的编码只有1位不同”，可以优化遗传算法的局部搜索能力。

以“相邻数`175`和`176`”为例：
- 普通二进制编码：`0010101111`→`0010110000`（5位不同）；
- 格雷码编码：`0010100100`→`0010101100`（仅1位不同）。

这种特性让遗传算法的**局部搜索更平滑**：微小的编码变化对应微小的变量变化，避免普通二进制“编码变多位、变量跳变”的问题。

- 遗传操作（交叉、变异）和普通二进制一样简单；
- 符合“最小字符集编码”（只用0/1），也适用模式定理分析；
- 解码时需通过“格雷码→二进制→十进制”的步骤（有固定转换公式）。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511210843390.png" width="300"/>

#### 10.1.2 初始化种群


初始化种群是遗传算法**开始阶段生成初始解集合**的步骤，是算法后续进化（交叉、变异等）的基础，核心概念和要点如下：

1\. **核心概念**

遗传算法里用“生物遗传术语”类比优化问题：
- **基因（Gene）**：编码后的最小单元（比如二进制编码里的1位0/1）；
- **染色体（Chromosome）/个体（Individual）**：1个“解”的完整编码（比如A1是一条染色体，由多个基因组成）；
- **种群（Population）**：多个个体（染色体）的集合（比如A1-A4组成一个种群）。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511210851394.png" width="300"/>

2\. **初始化的操作方式**

就是**生成n个初始个体（染色体）**，常用2种策略：
- **策略1（利用先验知识）**：如果知道解的大致分布（比如Shekel函数的最小值在4-5附近），就在这个区域内随机生成个体，能加快后续收敛；
- **策略2（冷启动）**：完全随机生成个体（覆盖整个解空间），适合对解分布无了解的情况，之后通过迭代优化。

3\. **种群规模的影响**
   
种群里个体的数量（n）要合理设置：
- 规模**过小**：种群多样性不足，容易“提前收敛”（没找到全局最优就停了）；
- 规模**过大**：计算量会增加，拖慢算法运行速度。

#### 10.1.3 遗传算子

定义三种随机算子, **选择**, **重组** 与 **变异** .生成状态空间 $ \Omega $ 上的 Markov 链 $X_{t}$ . 可以证明, 通过合适地定义上述三种随机算子，生成的链 {$ X_{t}$} 总是不可约的和非周期的，且收敛于一个稳定分布！

1\. **选择(selection)**

在遗传算法中，“选择”是**从当前种群里挑选优秀个体，让它们进入下一代繁衍**的核心操作，目的是保留适应度高（更接近最优解）的个体，推动种群进化。它的核心逻辑是“以适应度为权重，概率性地筛选个体”，常见策略有3种：

轮盘赌选择策略. 把种群的“适应度总和”比作一个“轮盘”，每个个体的适应度占轮盘的“扇形面积比例”，就是它被选中的概率。例如, 适应度高的个体（如图中“3”）占比38%，被选中的概率远高于适应度低的个体（如“2”仅占5%）。简单直接，但选择误差大, 可能漏掉优秀个体，或选入较差个体。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511210905973.png" width="300"/>

随机竞争选择. 先按轮盘赌选2个个体，再让这两个个体“竞争”——适应度高的那个被选中，重复这个过程直到选满种群规模。类似“淘汰赛”，能减少轮盘赌的随机误差，更倾向选优秀个体。

最佳保留选择. 分两步：
① 先按轮盘赌选大部分个体；
② 把当前种群中**适应度最高的个体直接复制到下一代**（避免优秀个体被随机操作淘汰）。
- 特点：既能保留优秀个体，又兼顾种群多样性，是常用的“保优”策略。

2\. **交叉(crossover)**

**二进制编码**：通常方式是1步交叉，即将父母一方的k位初始序列取代第二个亲本的初始k个位置形成新的数位串，以产生后代，其中位置k被随机选择。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511210908407.png" width="400"/>

**实值编码**：先随机选择2个parent，然后选择部分进行交换：比如群体的size是N，先选择最好的M个，就需要在产生N-M个才能维持好种群的大小。假设每个染色体的长度是K，那么先把M个种群中的染色体的第一个基因，按照倍数复制成长度为N-M，接着随机再给这个N-M排序下，组成了N-M个后代的第一个基因，以此类推，就完成了任意2个parent的基因交换和重组。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511210908859.png" width="400"/>

3\. **变异(mutation)**

二进制编码：随机选择二进制串的一位或多位进行翻转或逆序

实数值编码：遍历N个染色体上的K个基因，然后产生随机数，如果这个随机数小于X，就给这个基因做mutation，如果大于则不更改，具体的实现的时候可以灵活处理。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511210909803.png" width="600"/>


#### 10.1.4 遗传算法的流程

遗传算法的流程是 **生成初始解→迭代优化→输出最优解** 的循环过程，核心是通过“选择、交叉、变异”模拟生物进化，逐步找到更优的解。具体步骤（结合图中逻辑）如下：

1\. 初始化种群
生成一批初始个体（解的编码形式），作为算法的“初始候选解集合”。

2\. 计算适应度
对种群中每个个体，计算其**适应度**. 比如求最小值时，函数值越小则适应度越高。

3\. 选择
以“适应度为权重”中，从当前种群中筛选出部分个体，作为“繁衍下一代的父/母本”。例如, 依照公式 $ p_i = \frac{f_i}{\sum_{i=1}^n f_i} $ 抽取个体 $x_{i}$ , 其中 $f_i$ 是个体的适应度

4\. 遗传（复制、交叉、变异）
对选中的个体，按概率执行3种操作（要求 $ p_r + p_c + p_m = 1 $，即三个操作的概率和为1）：
- **复制**（概率 $ p_r $）：直接把优秀个体复制到下一代；
- **交叉**（概率 $ p_c $）：让两个个体交换部分编码（类似“基因重组”），生成新个体；
- **变异**（概率 $ p_m $）：随机改变个体的某一位编码（类似“基因突变”），增加种群多样性。

5\. 终止条件判断
重复步骤2-4，直到满足终止条件：
- 达到最大迭代次数/运行时间（比如1万代）；
- 种群的适应度不再显著变化（说明已接近最优解）。

6\. 输出结果
终止后，输出种群中适应度最高的个体，作为最终的最优解。

### 10.2 n:m 积和式优化问题

**行列式 ($\det(C)$)**：我们在计算行列式时，对不同排列的乘积项会根据逆序数的奇偶性加上正号或负号（即公式中的 $\operatorname{sign}(\sigma)$）。
$$\det(C) = \sum_{\sigma} \text{sign}(\sigma) \prod_{i=1}^{n} c_{i,\sigma(i)}$$

**积和式 ($\operatorname{perm}(C)$)**：积和式的定义与行列式非常相似，唯一的区别是**没有符号项**。它将所有排列的乘积直接相加。
$$\operatorname{perm}(C) = \sum_{\sigma} \prod_{i=1}^{n} c_{i, \sigma(i)}$$
简单来说，就是从矩阵的每一行取一个元素，确保这些元素不在同一列，将它们乘起来，然后把所有可能的这种组合加在一起。运算量为 $O(n!)$，这是一个非常巨大的计算量，比行列式的计算难得多。

积和式的性质:
- 若𝐶中有一个0元素，则积和式中有(n-1)!项为0
- 若𝐶的某一行或某一列元素为0，则积和式为0
- 交换矩阵的任意两行（列）不改变积和式的值

$n:m$ 积和式优化问题是一个**组合优化问题**。

* **设定**：
    1.  你有一个 $n$ 阶方阵（$n \times n$ 的格子）。
    2.  这是一个 **0-1 矩阵**（格子里的数字只能是 0 或 1）。
    3.  你手里总共有 **$m$ 个 "1"**（即矩阵中元素为 1 的个数总和是 $m$）。
* **目标**：
    你需要把这 $m$ 个 "1" 填入 $n \times n$ 的格子中，使得最后计算出来的**积和式 ($\operatorname{perm}(C)$) 的值最大**。


#### <span style="color: #4F845C;">举个例子, 3:5 积和式问题</span>

下面是一个具体的例子：
* **$n = 3$**：这是一个 3阶矩阵。
* **$m = 5$**：矩阵里总共有 5 个 "1"。
* **结果**：最大积和式是 **2**。

**为什么是 2？让我们看 PPT 中的矩阵例子：**
$$
\begin{pmatrix}
1 & 1 & 0 \\
1 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}
$$

**如何计算这个矩阵的积和式？**
我们需要找出所有“每行取一个，每列取一个”且元素都为 1 的组合：
1.  取 $c_{11}, c_{22}, c_{33}$ (即 $1 \times 1 \times 1$) = 1
2.  取 $c_{12}, c_{21}, c_{33}$ (即 $1 \times 1 \times 1$) = 1
3.  其他任何组合都会包含至少一个 0（例如 $c_{13}$ 是 0）。

所以，$\operatorname{perm}(C) = 1 + 1 = 2$。

**关于矩阵的不唯一性：**

$$
\text{perm}\begin{pmatrix}
0 & 0 & 1 \\
1 & 1 & 0 \\
1 & 1 & 0
\end{pmatrix}
= \text{perm}\begin{pmatrix}
1 & 0 & 1 \\
0 & 1 & 0 \\
1 & 0 & 1
\end{pmatrix}
= 2.
$$

这里展示了另外两个矩阵，它们的形状不同（行或列交换了），但积和式的结果也是 2。这对应了左下角框中的性质 3：**"交换矩阵的任意两行（列）不改变积和式的值"**。这意味着在优化问题中，我们关心的是 1 的**相对结构**（比如是否形成了紧密的块状），而不是它们的绝对位置。

**$n:m$ 积和式优化问题**就是在问：
<span style="font-size: 20px; color: #C25759;">给定 $n \times n$ 的空间和 $m$ 个资源（1），如何布局这些资源，才能让“全排列匹配”的路径数量最多？</span>

* 如果 $m < n$，积和式一定是 0（因为无法选出 $n$ 个 1）。
* 如果 $m = n^2$（全 1 矩阵），积和式是 $n!$。
* 这个问题的难点在于当 $n < m < n^2$ 时，如何分布这些 1 来最大化结果。

#### 10.2.2 使用遗传算法解积和式优化问题

1\. **定义染色体**. 用 $m$ 个 1 的 $n$ 阶 0-1 矩阵作为染色体。

> **回顾编码原则**
> - **有意义**：应使用能易于与所求问题相关。
> - **最小字符集**。

2\. **定义适应度函数**. 即矩阵的积和式 $\operatorname{perm}()$. 数值越大，说明该个体的“基因”越好，被遗传到下一代的概率就越高。

3\. 定义遗传算子（变异和交叉）. 

**变异**：东南西北环绕式的领域交换. 可以看到中心有一个深色格子（代表 1），周围标有 **E (East), W (West), N (North), S (South)** 的格子。这是一个**局部搜索**策略。不是在矩阵里随机找个地方把 0 变成 1，而是选中一个现有的 1，将其移动到它相邻（上、下、左、右）的空白位置（0）。这种“微调”可以避免破坏矩阵的整体结构，尝试在局部寻找更优解。


<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511211112551.png" width="500"/>

Matlab实现方法

```matlab
function childmat = mutate(childmat)
[lx,ly] = size(childmat);
x = randi(lx); % 随机生成整数索引。
y = randi(ly);
% “东南西北环绕式的领域交换”
% 构建候选邻居坐标数组
ewns = [x+1, x-1, x, x; y, y, y-1, y+1];  
for i = 1:8 % 超出边界的情况周期化，如左图
    if ewns(i) == 0 % 上面溢出处理, 设为最大值
    ewns(i) = lx;
    elseif ewns(i) == lx+1 % 下面溢出处理, 设为1
    ewns(i) = 1;
    end
end
for i = 1:4 % 交换循环
    coord = ewns(i,:);
    if childmat(coord(1), coord(2)) ~= childmat(x,y)
        childmat(coord(1), coord(2)) = …
        1 - childmat(coord(1), coord(2));childmat(x,y) = 1 - childmat(x,y);
    end
end
```

Python实现方法, 在python中实现这个可以使用**取模运算(%)**

```python
def mutation_nsew(matrix):
    """
    基于 PPT 描述的 '东南西北环绕式领域交换' 变异算子。
    """
    rows, cols = matrix.shape
    mutated_matrix = matrix.copy()
    
    # 1. 随机选择一个中心点
    x = np.random.randint(0, rows)
    y = np.random.randint(0, cols)
    
    # 2. 定义东南西北四个方向的偏移量 (dx, dy)
    directions = [
        (-1, 0), # North
        (1, 0),  # South
        (0, -1), # West
        (0, 1)   # East
    ]
    
    # 为了增加随机性，打乱尝试方向的顺序
    np.random.shuffle(directions)
    
    # 3. 遍历邻居并尝试交换
    for dx, dy in directions:
        # 计算邻居坐标，使用取模运算 (%) 实现环绕/穿墙效果
        # 例如：如果 x=-1，python 的 -1 % rows 会自动变成 rows-1 (最后一行)
        nx = (x + dx) % rows
        ny = (y + dy) % cols
        
        # 4. 如果中心点和邻居点的值不同 (即一个是0，一个是1)
        if mutated_matrix[x, y] != mutated_matrix[nx, ny]:
            # 交换两者
            mutated_matrix[x, y], mutated_matrix[nx, ny] = \
                mutated_matrix[nx, ny], mutated_matrix[x, y]
            
            # 变异通常只发生一次即可，交换成功后立即退出
            break
            
    return mutated_matrix
```


**交叉**：**模板化全局交换.** 设矩阵A和B是被选出来进行交换的两个矩阵。首先，将矩阵的元素按行的顺序依次头为相接地排成**一维数组**，并将数组地头尾连成环绕地形式。然后，随机选出一个共同的起点位置，沿着两个数组的元素**向后移动直到第一次出现两个不同的元素**，则交换这两个元素，继续沿着数组的元素移动，不断地及进行类似的交换元素，这个过程直至遇到第一次出现不同元素的位置时结束。


Matlab实现方法

```matlab
function newmat = crossover(mat1, mat2)
[m, n] = size(mat1); % 获取矩阵尺寸
% 一种实现方式，可向量化优化之
for i = 1:m 
    for j = 1:n % 遍历矩阵每一个格子
        if mat1(i, j) ~= mat2(i, j) % 检查两个矩阵在同一位置的值是否不同
            mat1(i, j) = 1 - mat1(i, j);
            mat2(i, j) = 1 - mat2(i, j); % 这是 MATLAB 中常用的位翻转技巧。
            % 如果是 0，1-0=1；如果是 1，1-1=0。这行代码实现了值的交换
        end
    end
end
newmat = mat1;
end
```


<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511211055949.png" width="400"/>


Python实现方法

```python
import numpy as np

def crossover_conserved(parent_a, parent_b):
    """
    基于 PPT 描述的 '模板化全局交换' 交叉算子。
    核心逻辑：在保持 1 的总数不变的前提下交换基因。
    """
    # 复制父代，避免修改原始数据
    child_a = parent_a.copy()
    child_b = parent_b.copy()
    
    rows, cols = parent_a.shape
    # 1. 扁平化：将矩阵展平为一维数组
    flat_a = child_a.flatten()
    flat_b = child_b.flatten()
    total_len = len(flat_a)
    
    # 2. 随机起点
    start_idx = np.random.randint(0, total_len)
    
    # 记录 '1' 的盈亏情况。
    # balance > 0 表示 A 多了 1 (B 少了 1)
    # balance < 0 表示 A 少了 1 (B 多了 1)
    balance = 0 
    
    # 3. 环绕遍历 (最多遍历一圈)
    for k in range(total_len):
        # 环绕索引
        idx = (start_idx + k) % total_len
        
        # 如果两个位置元素不同，尝试交换
        if flat_a[idx] != flat_b[idx]:
            # 执行交换
            flat_a[idx], flat_b[idx] = flat_b[idx], flat_a[idx]
            
            # 更新平衡状态
            # 如果 flat_a 现在变成了 1 (说明原来是 0)，balance + 1
            # 如果 flat_a 现在变成了 0 (说明原来是 1)，balance - 1
            if flat_a[idx] == 1:
                balance += 1
            else:
                balance -= 1
            
            # 4. 终止条件：如果平衡回归为 0，且不仅仅是因为刚开始，说明完成了一次闭环交换
            if balance == 0:
                break
    
    # 将一维数组重新塑形回矩阵
    return flat_a.reshape(rows, cols), flat_b.reshape(rows, cols)
```

算例主程序

种群参数

```matlab
popnum = 12; % 种群大小 (Population Size)。每一代有 12 个矩阵个体。
n = 3; % 阶数
m = 5; % 1的个数
maxGen = 1000;
perm_GA(popnum,n,m,maxGen); % 最大迭代次数。繁衍 1000 代后停止。
```

遗传过程

```matlab
% 轮盘赌选择(实际上是锦标赛选择, 随机选几个人出来打架，最强的那个胜出)
tournamentSize = 4; %设置大小
for k=1:popnum % 生成新一代 , 我们要生成与上一代数量相同的新个体
    % 选择父代
    tourPopDistances = zeros(tournamentSize, 1); % 建立一个临时名单，用来存参赛选手的成绩。
    % 随机从种群中抽取 4 个幸运观众（randi(popnum) 生成随机索引）
    % 并把他们的适应度（存放在 B 数组中）记录下来
    for i = 1:tournamentSize
        randomRow = randi(popnum);tourPopDistances(i,1) = B(randomRow);
    end 
    % 选择最好的A, 找出这 4 个人里适应度最高的那个数值
    parent1 = max(tourPopDistances);
    % 根据这个最高适应度值，去原始种群矩阵库 mat 中把对应的矩阵实体取出来
    parent1mat = mat(:, :, find(B==parent1, 1)); 
    for i = 1:tournamentSize
        randomRow = randi(popnum);
        tourPopDistances(i,1) = B(randomRow);
    end
    % 选择最好的B
    parent2 = max(tourPopDistances);
    parent2mat = mat(:, :, find(B==parent2, 1)); 
    % 执行交叉
    submat = crossover(parent1mat, parent2mat);
    % 执行变异
    submat = mutate(submat); 
    % 获得新的一代
    offspring(:, :, k) = submat;
end
```

#### 10.2.3 粘滞现象及修正

**粘滞现象 (早熟现象)** : 遗传算法在迭代过程中，适应度的改善速度会越来越慢，最终 “陷入” 局部最优解（而不是找到全局最优），这就是粘滞 / 早熟现象。

**修正方法**: 核心思路是**扩大交叉操作的群体范围**，打破当前的局部最优束缚; 让当前群体的状态，和整个可选状态空间里的任意 / 随机状态进行交叉，而不是只和当前群体内的个体交叉。引入更多多样性，帮助算法跳出局部最优，向全局最优靠近。

<img src="https://zzh123-1325455460.cos.ap-nanjing.myqcloud.com/202511211459916.png" width="400"/>

#### 10.2.4 模式定理 (Schema Theorem)

<span style="font-size: 20px; color: #4F845C;">模式定理是遗传算法的核心理论，它解释了 “优秀模式” 在遗传迭代中会指数级增长的规律. </span>


- **模式（Schema）**：是遗传算法中字符串（个体）的 “相似片段”，可以理解为一种具有共性特征的基因片段。
- **确定位数（阶）**：模式中固定字符的数量（越少越好）；
- **定义长度**：模式中第一个和最后一个固定字符的距离（越短越好）；
- **适应度**：模式对应的个体的平均适应度。

在遗传算法的选择、交叉、变异操作作用下, 
<span style="font-size: 20px; color: #C25759;">确定位数少、定义长度短、且平均适应度高于种群平均的模式（即 “优秀模式”），会在子代种群中呈指数级增长。</span>

**模式定理的证明:**

先明确符号定义
- $ m(H,t) $：第$ t $代中，属于模式$ H $的个体数量；
- $ p_i = \frac{f_i}{\sum_{i=1}^n f_i} $：个体$ A_i $被选择的概率（适应度越高，概率越大）；
- $ \bar{f} = \frac{\sum_{i=1}^n f_i}{n} $：种群的平均适应度；
- $ f(H) $：模式$ H $对应的所有个体的平均适应度。

选择操作后模式 $H$ 的数量变化. 当用新种群（非重叠的$ n $个串）代替旧种群时：
每个属于模式$ H $的个体，被选中的概率是$ \frac{f(H)}{\sum_{i=1}^n f_i} $（因为模式$ H $的平均适应度是$ f(H) $）。
因此，第$ t+1 $代中模式$ H $的数量为：

$$
m(H,t+1) = m(H,t) \times n \times \frac{f(H)}{\sum_{i=1}^n f_i}
$$

又因为$ \bar{f} = \frac{\sum_{i=1}^n f_i}{n} $，即$ \sum_{i=1}^n f_i = n\bar{f} $，代入后化简得：

$$
m(H,t+1) = m(H,t) \times \frac{f(H)}{\bar{f}}
$$

假设模式$ H $的适应度比种群平均高$ c\bar{f} $（即$ f(H) = (1+c)\bar{f} $，$ c>0 $代表“优秀”），代入上式：

$$
m(H,t+1) = m(H,t) \times \frac{(1+c)\bar{f}}{\bar{f}} = m(H,t) \times (1+c)
$$

以此类推，迭代$ t $代后，模式$ H $的数量会变成：

$$
m(H,t) = (1+c)^t \times m(H,0)
$$

这就证明了： **适应度高于种群平均的模式，在选择操作下会呈指数级增长** 。


## 神经网络模拟


> 还没上呢


## 扩散采样


> 还没上呢


## KMC -- 分子动力学



> 还没上呢

## SOE

> 还没上呢

## 复杂网络与元胞自动机


> 还没上呢
